# -*- coding: utf-8 -*-
"""k_fold_cross_validation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/141P7V80ao0P8tOWGvhNkSa4QIuepeUJX

# KFold Cross Validation
"""

from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
import numpy as np
from sklearn.datasets import load_digits
import matplotlib.pyplot as plt
digits = load_digits()

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(digits.data,digits.target,test_size=0.3)

"""**Logistic Regression**"""

lr = LogisticRegression(solver='liblinear',multi_class='ovr')
lr.fit(X_train, y_train)
lr.score(X_test, y_test)

"""**SVM**"""

svm = SVC(gamma='auto')
svm.fit(X_train, y_train)
svm.score(X_test, y_test)

"""**Random Forest**"""

rf = RandomForestClassifier(n_estimators=40)
rf.fit(X_train, y_train)
rf.score(X_test, y_test)

"""**KFold cross validation**

Basic example
"""

from sklearn.model_selection import KFold
kf = KFold(n_splits=3)
kf

for train_index, test_index in kf.split([1,2,3,4,5,6,7,8,9]):
    print(train_index, test_index)

"""**Use KFold for our digits example**"""

def get_score(model, X_train, X_test, y_train, y_test):
    model.fit(X_train, y_train)
    return model.score(X_test, y_test)

from sklearn.model_selection import StratifiedKFold
folds = StratifiedKFold(n_splits=3)

scores_logistic = []
scores_svm = []
scores_rf = []

for train_index, test_index in folds.split(digits.data,digits.target):
    X_train, X_test, y_train, y_test = digits.data[train_index], digits.data[test_index], \
                                       digits.target[train_index], digits.target[test_index]
    scores_logistic.append(get_score(LogisticRegression(solver='liblinear',multi_class='ovr'), X_train, X_test, y_train, y_test))
    scores_svm.append(get_score(SVC(gamma='auto'), X_train, X_test, y_train, y_test))
    scores_rf.append(get_score(RandomForestClassifier(n_estimators=40), X_train, X_test, y_train, y_test))

scores_logistic

scores_svm

scores_rf

"""**cross_val_score function**"""

from sklearn.model_selection import cross_val_score

"""Logistic regression model performance using **cross_val_score**"""

cross_val_score(LogisticRegression(solver='liblinear',multi_class='ovr'), digits.data, digits.target,cv=3)

"""
svm model performance using **cross_val_score**"""

cross_val_score(SVC(gamma='auto'), digits.data, digits.target,cv=3)

"""random forest performance using **cross_val_score**"""

cross_val_score(RandomForestClassifier(n_estimators=40),digits.data, digits.target,cv=3)

"""**Parameter tunning using k fold cross validation**"""

scores1 = cross_val_score(RandomForestClassifier(n_estimators=5),digits.data, digits.target, cv=10)
np.average(scores1)

scores2 = cross_val_score(RandomForestClassifier(n_estimators=20),digits.data, digits.target, cv=10)
np.average(scores2)

scores3 = cross_val_score(RandomForestClassifier(n_estimators=30),digits.data, digits.target, cv=10)
np.average(scores3)

scores4 = cross_val_score(RandomForestClassifier(n_estimators=40),digits.data, digits.target, cv=10)
np.average(scores4)

"""# Exercise"""

from sklearn.datasets import load_iris
from sklearn.model_selection import cross_val_score
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
import numpy as np

iris = load_iris()

"""
**Logistic Regression**"""

l_scores = cross_val_score(LogisticRegression(), iris.data, iris.target)
l_scores

np.average(l_scores)

"""**Decision Tree**"""

d_scores = cross_val_score(DecisionTreeClassifier(), iris.data, iris.target)
d_scores

np.average(d_scores)

"""**Support Vector Machine (SVM)**"""

s_scores = cross_val_score(SVC(), iris.data, iris.target)
s_scores

np.average(s_scores)

"""**Random Forest**"""

r_scores = cross_val_score(RandomForestClassifier(n_estimators=40), iris.data, iris.target)
r_scores

np.average(r_scores)

"""**Best score so far is from SVM: 0.97344771241830064**"""